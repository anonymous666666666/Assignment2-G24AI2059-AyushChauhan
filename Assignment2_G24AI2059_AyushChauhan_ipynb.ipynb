{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqlEEm0wosLJAGokQPbroQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anonymous666666666/Assignment2-G24AI2059-AyushChauhan/blob/main/Assignment2_G24AI2059_AyushChauhan_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7Yp6HnJMYL2",
        "outputId": "137e6818-fc73-4339-e4e0-345d752ebbdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from mrjob) (6.0.2)\n",
            "Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/439.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m368.6/439.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n",
            "--2025-07-26 14:50:50--  https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/cruise.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8734 (8.5K) [text/plain]\n",
            "Saving to: ‘cruise.csv’\n",
            "\n",
            "cruise.csv          100%[===================>]   8.53K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-07-26 14:50:50 (15.4 MB/s) - ‘cruise.csv’ saved [8734/8734]\n",
            "\n",
            "--2025-07-26 14:50:50--  https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/customer_churn.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 115479 (113K) [text/plain]\n",
            "Saving to: ‘customer_churn.csv’\n",
            "\n",
            "customer_churn.csv  100%[===================>] 112.77K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-07-26 14:50:50 (3.04 MB/s) - ‘customer_churn.csv’ saved [115479/115479]\n",
            "\n",
            "--2025-07-26 14:50:51--  https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/e-com_customer.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86871 (85K) [text/plain]\n",
            "Saving to: ‘ecom_customer.csv’\n",
            "\n",
            "ecom_customer.csv   100%[===================>]  84.83K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-07-26 14:50:51 (2.56 MB/s) - ‘ecom_customer.csv’ saved [86871/86871]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install mrjob and Java for Hadoop compatibility in Colab\n",
        "!pip install mrjob\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download datasets using wget\n",
        "!wget -O \"cruise.csv\" https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/cruise.csv\n",
        "!wget -O \"customer_churn.csv\" https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/customer_churn.csv\n",
        "!wget -O \"ecom_customer.csv\" https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/e-com_customer.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Cruiseline Aggregations (5 marks)\n",
        "#Using cruise.csv, implement an mrjob class that computes, for each Cruise line:\n",
        "#(a) Total number of ships.\n",
        "#(b) Average Tonnage (to two decimals).\n",
        "#(c) Maximum crew size.\n",
        "#Optional) Use a Combiner for partial aggregation.\n",
        "\n",
        "\n",
        "%%file CruiselineAggregation.py\n",
        "from mrjob.job import MRJob\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "class CruiselineAggregation(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        reader = csv.reader(StringIO(line))\n",
        "        row = next(reader)\n",
        "        if row[0] == \"Ship_name\":\n",
        "            return\n",
        "\n",
        "        cruise_line = row[1]\n",
        "        try:\n",
        "            tonnage = float(row[3])\n",
        "            crew = float(row[5])\n",
        "        except ValueError:\n",
        "            return\n",
        "\n",
        "        yield cruise_line, (1, tonnage, crew)\n",
        "\n",
        "    def combiner(self, cruise_line, values):\n",
        "        total_ships, total_tonnage, max_crew = 0, 0.0, 0.0\n",
        "        for count, tonnage, crew in values:\n",
        "            total_ships += count\n",
        "            total_tonnage += tonnage\n",
        "            max_crew = max(max_crew, crew)\n",
        "        yield cruise_line, (total_ships, total_tonnage, max_crew)\n",
        "\n",
        "    def reducer(self, cruise_line, values):\n",
        "        total_ships, total_tonnage, max_crew = 0, 0.0, 0.0\n",
        "        for count, tonnage, crew in values:\n",
        "            total_ships += count\n",
        "            total_tonnage += tonnage\n",
        "            max_crew = max(max_crew, crew)\n",
        "\n",
        "        avg_tonnage = round(total_tonnage / total_ships, 2)\n",
        "        yield cruise_line, {\n",
        "            \"Total Ships\": total_ships,\n",
        "            \"Avg Tonnage\": avg_tonnage,\n",
        "            \"Max Crew\": max_crew\n",
        "        }\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    CruiselineAggregation.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgJxPySXN3XT",
        "outputId": "0374859c-b601-4b3b-e8c0-d68b57cafa26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CruiselineAggregation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python CruiselineAggregation.py cruise.csv > q4_output.txt\n",
        "!cat q4_output.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0A9J6ifOnyT",
        "outputId": "7fb63a2b-44d1-45b0-9e10-61a7c95a6637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/CruiselineAggregation.root.20250726.145728.428034\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/CruiselineAggregation.root.20250726.145728.428034/output\n",
            "Streaming final output from /tmp/CruiselineAggregation.root.20250726.145728.428034/output...\n",
            "Removing temp directory /tmp/CruiselineAggregation.root.20250726.145728.428034...\n",
            "\"Cunard\"\t{\"Total Ships\": 3, \"Avg Tonnage\": 103.91, \"Max Crew\": 11.32}\n",
            "\"Disney\"\t{\"Total Ships\": 2, \"Avg Tonnage\": 83.17, \"Max Crew\": 9.64}\n",
            "\"Holland_American\"\t{\"Total Ships\": 14, \"Avg Tonnage\": 60.5, \"Max Crew\": 9.59}\n",
            "\"MSC\"\t{\"Total Ships\": 8, \"Avg Tonnage\": 63.77, \"Max Crew\": 10.93}\n",
            "\"Norwegian\"\t{\"Total Ships\": 13, \"Avg Tonnage\": 63.72, \"Max Crew\": 9.65}\n",
            "\"Oceania\"\t{\"Total Ships\": 3, \"Avg Tonnage\": 30.28, \"Max Crew\": 5.94}\n",
            "\"Orient\"\t{\"Total Ships\": 1, \"Avg Tonnage\": 22.08, \"Max Crew\": 5.78}\n",
            "\"P&O\"\t{\"Total Ships\": 6, \"Avg Tonnage\": 77.86, \"Max Crew\": 9.35}\n",
            "\"Princess\"\t{\"Total Ships\": 17, \"Avg Tonnage\": 87.54, \"Max Crew\": 9.64}\n",
            "\"Regent_Seven_Seas\"\t{\"Total Ships\": 5, \"Avg Tonnage\": 32.14, \"Max Crew\": 7.09}\n",
            "\"Royal_Caribbean\"\t{\"Total Ships\": 23, \"Avg Tonnage\": 107.01, \"Max Crew\": 11.82}\n",
            "\"Azamara\"\t{\"Total Ships\": 2, \"Avg Tonnage\": 30.28, \"Max Crew\": 5.94}\n",
            "\"Carnival\"\t{\"Total Ships\": 22, \"Avg Tonnage\": 84.65, \"Max Crew\": 9.63}\n",
            "\"Celebrity\"\t{\"Total Ships\": 10, \"Avg Tonnage\": 76.16, \"Max Crew\": 10.33}\n",
            "\"Costa\"\t{\"Total Ships\": 11, \"Avg Tonnage\": 71.1, \"Max Crew\": 9.6}\n",
            "\"Crystal\"\t{\"Total Ships\": 2, \"Avg Tonnage\": 59.5, \"Max Crew\": 7.9}\n",
            "\"Seabourn\"\t{\"Total Ships\": 3, \"Avg Tonnage\": 10.0, \"Max Crew\": 4.4}\n",
            "\"Silversea\"\t{\"Total Ships\": 4, \"Avg Tonnage\": 20.9, \"Max Crew\": 5.97}\n",
            "\"Star\"\t{\"Total Ships\": 6, \"Avg Tonnage\": 30.77, \"Max Crew\": 8.79}\n",
            "\"Windstar\"\t{\"Total Ships\": 3, \"Avg Tonnage\": 8.48, \"Max Crew\": 6.17}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Company Churn Rate (5 marks)\n",
        "#From customer churn.csv, create a MultiStepJob:\n",
        "#Step 1: Mapper emits (Company, TOTAL) and (Company, CHURNED) where Churn==1.\n",
        "#Step 2: Reducer computes churn rate = CHURNED\n",
        "#TOTAL , outputting four-decimal floats.\n",
        "#Use a small VIP companies.txt in the distributed cache to restrict to listed companies.\n",
        "#Provide a sample file with at least three names.\n",
        "\n",
        "\n",
        "%%file vip_companies.txt\n",
        "harvey llc\n",
        "wilson plc\n",
        "smith inc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR6SveHVPW9k",
        "outputId": "7b4785da-6484-4093-f0a2-87bd14546a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vip_companies.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file CompanyChurnRate.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "class CompanyChurnRate(MRJob):\n",
        "\n",
        "    def configure_args(self):\n",
        "        super().configure_args()\n",
        "        self.add_file_arg('--vip_companies')\n",
        "\n",
        "    def load_vip_companies(self):\n",
        "        # Load and normalize VIP companies (lowercase and strip)\n",
        "        with open(self.options.vip_companies, 'r') as f:\n",
        "            return set(line.strip().lower() for line in f)\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper_init=self.mapper_init,\n",
        "                   mapper=self.mapper,\n",
        "                   reducer=self.reducer_compute_churn_rate)\n",
        "        ]\n",
        "\n",
        "    def mapper_init(self):\n",
        "        self.vip_set = self.load_vip_companies()\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        reader = csv.reader(StringIO(line))\n",
        "        row = next(reader)\n",
        "\n",
        "        # Skip header row or rows with invalid churn value\n",
        "        try:\n",
        "            churn = int(row[-1])\n",
        "        except ValueError:\n",
        "            return\n",
        "\n",
        "        company = row[8].strip().lower()  # Normalize company name from CSV\n",
        "\n",
        "        if company in self.vip_set:\n",
        "            yield company, ('TOTAL', 1)\n",
        "            if churn == 1:\n",
        "                yield company, ('CHURNED', 1)\n",
        "\n",
        "    def reducer_compute_churn_rate(self, company, values):\n",
        "        total, churned = 0, 0\n",
        "        for label, count in values:\n",
        "            if label == 'TOTAL':\n",
        "                total += count\n",
        "            elif label == 'CHURNED':\n",
        "                churned += count\n",
        "\n",
        "        if total > 0:\n",
        "            churn_rate = round(churned / total, 4)\n",
        "            yield company, churn_rate\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    CompanyChurnRate.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_wlD8UtPel4",
        "outputId": "10052030-0701-4c9b-f4f2-e463fb6329f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CompanyChurnRate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python CompanyChurnRate.py \"customer_churn.csv\" --vip_companies vip_companies.txt > churn_output.txt\n",
        "\n",
        "with open(\"churn_output.txt\", \"r\") as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GCmyPYVPipZ",
        "outputId": "64f5c83d-1e5c-4682-e048-f16c5d926abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/CompanyChurnRate.root.20250726.145930.290007\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/CompanyChurnRate.root.20250726.145930.290007/output\n",
            "Streaming final output from /tmp/CompanyChurnRate.root.20250726.145930.290007/output...\n",
            "Removing temp directory /tmp/CompanyChurnRate.root.20250726.145930.290007...\n",
            "\"wilson plc\"\t0.3333\n",
            "\"harvey llc\"\t1.0\n",
            "\"smith inc\"\t1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. State-wise Spending (5 marks)\n",
        "#From e-com customer.csv, extract the two-letter state code from the Address field.\n",
        "#Then:\n",
        "#• Mapper parses the state.\n",
        "#• Reducer sums Yearly Amount Spent per state.\n",
        "#• Output the top 5 states by total spending.\n",
        "\n",
        "\n",
        "\n",
        "%%file StatewiseSpending.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "from io import StringIO\n",
        "from heapq import nlargest\n",
        "\n",
        "class StatewiseSpending(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        reader = csv.reader(StringIO(line))\n",
        "        row = next(reader)\n",
        "\n",
        "        # Skip header\n",
        "        if row[0] == \"Email\":\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            address = row[1].strip()  # Correct index for Address\n",
        "            amount_spent = float(row[6])  # Correct index for Yearly Amount Spent\n",
        "        except:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Get state from the last comma-separated segment\n",
        "            parts = address.split(',')\n",
        "            if len(parts) < 2:\n",
        "                return\n",
        "            state_zip = parts[-1].strip().split()\n",
        "            state = state_zip[0] if len(state_zip) > 0 else \"\"\n",
        "        except IndexError:\n",
        "            return\n",
        "\n",
        "        if len(state) == 2:\n",
        "            yield state, amount_spent\n",
        "\n",
        "    def reducer(self, state, amounts):\n",
        "        yield None, (sum(amounts), state)\n",
        "\n",
        "    def reducer_find_top_5(self, _, state_amount_pairs):\n",
        "        top5 = nlargest(5, state_amount_pairs)\n",
        "        for amount, state in top5:\n",
        "            yield state, round(amount, 2)\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper,\n",
        "                   reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_find_top_5)\n",
        "        ]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    StatewiseSpending.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlR9-wmTP0Px",
        "outputId": "724d21c5-43bb-429d-9054-6d93aef8a410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting StatewiseSpending.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python StatewiseSpending.py \"ecom_customer.csv\" > state_spending_output.txt\n",
        "\n",
        "with open(\"state_spending_output.txt\", \"r\") as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRA-AxoBP_UE",
        "outputId": "4b554dd8-2585-4a44-b090-d1a0b5008cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/StatewiseSpending.root.20250726.150137.410588\n",
            "Running step 1 of 2...\n",
            "Running step 2 of 2...\n",
            "job output is in /tmp/StatewiseSpending.root.20250726.150137.410588/output\n",
            "Streaming final output from /tmp/StatewiseSpending.root.20250726.150137.410588/output...\n",
            "Removing temp directory /tmp/StatewiseSpending.root.20250726.150137.410588...\n",
            "\"SC\"\t53.64\n",
            "\"DE\"\t49.69\n",
            "\"MO\"\t45.63\n",
            "\"MN\"\t44.99\n",
            "\"VT\"\t44.22\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Two-step Ship Filter & Median Length (5 marks)\n",
        "#On cruise.csv, implement a two-step mrjob pipeline:\n",
        "#Step 1: Filter ships with passenger density > 35.0; emit ⟨Cruise line, length⟩.\n",
        "#Step 2: Compute the median of the lengths per Cruise line, handling even/odd counts\n",
        "#correctly.\n",
        "#Use the steps() API and output medians to two decimals.\n",
        "\n",
        "\n",
        "\n",
        "%%file CruiseMedianLength.py\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "class CruiseMedianLength(MRJob):\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper_init=self.mapper_init,\n",
        "                   mapper=self.mapper_filter_density,\n",
        "                   reducer=self.reducer_collect_lengths),\n",
        "            MRStep(reducer=self.reducer_compute_median)\n",
        "        ]\n",
        "\n",
        "    def mapper_init(self):\n",
        "        self.header_processed = False\n",
        "\n",
        "    def mapper_filter_density(self, _, line):\n",
        "        reader = csv.reader(StringIO(line))\n",
        "        row = next(reader)\n",
        "\n",
        "        # Skip header row\n",
        "        if not self.header_processed and \"Ship_name\" in row:\n",
        "            self.header_processed = True\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            cruise_line = row[1]\n",
        "            density = float(row[7])  # passenger_density\n",
        "            length = float(row[5])   # length\n",
        "        except:\n",
        "            return\n",
        "\n",
        "        if density > 35.0:\n",
        "            yield cruise_line, length\n",
        "\n",
        "    def reducer_collect_lengths(self, cruise_line, lengths):\n",
        "        yield cruise_line, sorted(lengths)\n",
        "\n",
        "    def reducer_compute_median(self, cruise_line, lengths_lists):\n",
        "        all_lengths = []\n",
        "        for lst in lengths_lists:\n",
        "            all_lengths.extend(lst)\n",
        "\n",
        "        all_lengths.sort()\n",
        "        n = len(all_lengths)\n",
        "        if n == 0:\n",
        "            return\n",
        "\n",
        "        if n % 2 == 1:\n",
        "            median = all_lengths[n // 2]\n",
        "        else:\n",
        "            median = (all_lengths[n // 2 - 1] + all_lengths[n // 2]) / 2\n",
        "\n",
        "        yield cruise_line, round(median, 2)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    CruiseMedianLength.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "401amYi7QRTk",
        "outputId": "69544b3d-dcb3-4d94-c525-ee83c8838c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CruiseMedianLength.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python CruiseMedianLength.py cruise.csv > cruise_median_output.txt\n",
        "with open(\"cruise_median_output.txt\") as f:\n",
        "    print(f.read())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh9OSFO0QXVu",
        "outputId": "a835a400-0f58-46f8-daf7-b5adb5bfb8cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/CruiseMedianLength.root.20250726.150234.249721\n",
            "Running step 1 of 2...\n",
            "Running step 2 of 2...\n",
            "job output is in /tmp/CruiseMedianLength.root.20250726.150234.249721/output\n",
            "Streaming final output from /tmp/CruiseMedianLength.root.20250726.150234.249721/output...\n",
            "Removing temp directory /tmp/CruiseMedianLength.root.20250726.150234.249721...\n",
            "\"Cunard\"\t9.64\n",
            "\"Disney\"\t9.64\n",
            "\"Holland_American\"\t7.77\n",
            "\"MSC\"\t8.23\n",
            "\"Norwegian\"\t9.0\n",
            "\"Oceania\"\t5.94\n",
            "\"P&O\"\t8.56\n",
            "\"Princess\"\t9.51\n",
            "\"Regent_Seven_Seas\"\t6.15\n",
            "\"Royal_Caribbean\"\t10.2\n",
            "\"Azamara\"\t5.94\n",
            "\"Carnival\"\t9.52\n",
            "\"Celebrity\"\t9.65\n",
            "\"Costa\"\t8.28\n",
            "\"Crystal\"\t7.86\n",
            "\"Seabourn\"\t4.4\n",
            "\"Silversea\"\t5.55\n",
            "\"Star\"\t2.8\n",
            "\"Windstar\"\t6.17\n",
            "\n"
          ]
        }
      ]
    }
  ]
}